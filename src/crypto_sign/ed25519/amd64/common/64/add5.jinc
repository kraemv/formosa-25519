/**
 * function __add5_rrr
 * @param {reg u64[5]} f - first summand in 64-bit limb representation
 * @param {reg u64[5]} g - second summand in 64-bit limb representation
 * @returns {reg u64[4]} - Sum of f and g in 64-bit limb representation
 * 
 * This function adds the two numbers in f and g. Inputs are consumed.
 * f[4], g[4] < 256, hence no final carry can occur. The result is
 * reduced to 4 limbs.
 * The representation is:
 * h = f + g
 * h = 2**0*f0 + 2**64*f1 + 2**128*f2 + 2**192*f3 + 2**256*f4 +
 *     2**0*g0 + 2**64*g1 + 2**128*g2 + 2**192*g3 + 2**256*g4
*/
inline fn __add5_rrr(reg u64[5] f, reg u64[5] g) -> reg u64[4]
{
  reg u64[4] h; // Result
  reg bool cf; // Carry flag
  inline int i;

  // Add both numbers. No carry in limb 5.
  cf, f[0] += g[0];
  for i=1 to 5
  { cf, f[i] += g[i] + cf; }
  
  // Multiply MSBs by 2 and later 19 to get 38
  ?{}, f[4] = #SHLD(f[4], f[3], 1);
  // Clear shifted bit
  f[3] &= mask63;

  // Multiply upper limb by 19, as 2^256 == 38
  ?{}, f[4] = #IMULri ( f[4], 19 );
  // Reduce result
  cf, h[0] = f[0] + f[4];
  cf, h[1] = f[1] + 0 + cf;
  cf, h[2] = f[2] + 0 + cf;
  cf, h[3] = f[3] + 0 + cf; // No carry as MSB is cleared

  return h;
}

/**
 * function __add5_rrs
 * @param {reg u64[5]} f - first summand in 64-bit limb representation
 * @param {stack u64[5]} g - ptr to second summand in 64-bit limb representation
 * @returns {reg u64[4]} - Sum of f and g in 64-bit limb representation
 * 
 * This function adds the two numbers in f and g. Inputs are consumed.
 * f[4], g[4] < 256, hence no final carry can occur. The result is
 * reduced to 4 limbs.
 * The representation is:
 * h = f + g
 * h = 2**0*f0 + 2**64*f1 + 2**128*f2 + 2**192*f3 + 2**256*f4 +
 *     2**0*g0 + 2**64*g1 + 2**128*g2 + 2**192*g3 + 2**256*g4
*/
inline fn __add5_rrs(reg u64[5] f, stack u64[5] g) -> reg u64[4]
{
  reg u64[4] h; // Result
  reg bool cf; // Carry flag
  inline int i;
  
  // Add both numbers. No carry in limb 5.
  cf, f[0] += g[0];
  for i=1 to 5
  { cf, f[i] += g[i] + cf; }

  // Multiply MSBs by 2 and later 19 to get 38
  ?{}, f[4] = #SHLD(f[4], f[3], 1);
  // Clear shifted bit
  f[3] &= mask63;

  // Multiply upper limb by 19, as 2^256 == 38
  ?{}, f[4] = #IMULri ( f[4], 19 );
  // Reduce result
  cf, h[0] = f[0] + f[4];
  cf, h[1] = f[1] + 0 + cf;
  cf, h[2] = f[2] + 0 + cf;
  cf, h[3] = f[3] + 0 + cf; // No carry as MSB is cleared

  return h;
}

/**
 * function __add5_rrp
 * @param {reg u64[5]} f - first summand in 64-bit limb representation
 * @param {reg ptr u64[5]} g - ptr to second summand in 64-bit limb representation
 * @returns {reg u64[4]} - Sum of f and g in 64-bit limb representation
 * 
 * This function adds the two numbers in f and g. Inputs are consumed.
 * f[4], g[4] < 256 hence no final carry can occur. The result is
 * reduced to 4 limbs.
 * The representation is:
 * h = f + g
 * h = 2**0*f0 + 2**64*f1 + 2**128*f2 + 2**192*f3 + 2**256*f4 +
 *     2**0*g0 + 2**64*g1 + 2**128*g2 + 2**192*g3 + 2**256*g4
*/
inline fn __add5_rrp(reg u64[5] f, reg ptr u64[5] g) -> reg u64[4]
{
  reg u64[4] h; // Result
  reg bool cf; // Carry flag
  inline int i;
  
  // Add both numbers. No carry in limb 5.
  cf, f[0] += g[0];
  for i=1 to 5
  { cf, f[i] += g[i] + cf; }
  
  // Multiply MSBs by 2 and later 19 to get 38
  ?{}, f[4] = #SHLD(f[4], f[3], 1);
  // Clear shifted bit
  f[3] &= mask63;
  
  // Multiply upper limb by 19, as 2^256 == 38
  ?{}, f[4] = #IMULri ( f[4], 19 );
  // Reduce result
  cf, h[0] = f[0] + f[4];
  cf, h[1] = f[1] + 0 + cf;
  cf, h[2] = f[2] + 0 + cf;
  cf, h[3] = f[3] + 0 + cf; // No carry as MSB is cleared

  return h;
}

/**
 * function __add54_rrs
 * @param {reg u64[5]} f - first summand in 64-bit limb representation
 * @param {stack u64[4]} g - ptr to second summand in 64-bit limb representation
 * @returns {stack u64[4]} - Sum of f and g in 64-bit limb representation
 * 
 * This function adds the two numbers in f and g. Inputs are consumed.
 * f[4] < 256, hence no final carry can occur. The result is
 * reduced to 4 limbs.
 * The representation is:
 * h = f + g
 * h = 2**0*f0 + 2**64*f1 + 2**128*f2 + 2**192*f3 + 2**256*f4 +
 *     2**0*g0 + 2**64*g1 + 2**128*g2 + 2**192*g3 + 2**256*g4
*/
inline fn __add5_srs(reg u64[5] a, stack u64[5] b) -> stack u64[4]
{
  reg u64[4] c;
  stack u64[4] cs;

  c = __add5_rrs(a, b);
  cs = #copy(c);

  return cs;
}

/**
 * function __add54_rrs
 * @param {reg u64[5]} f - first summand in 64-bit limb representation
 * @param {stack u64[4]} g - ptr to second summand in 64-bit limb representation
 * @returns {reg u64[4]} - Sum of f and g in 64-bit limb representation
 * 
 * This function adds the two numbers in f and g. Inputs are consumed.
 * f[4] < 256, hence no final carry can occur. The result is
 * reduced to 4 limbs.
 * The representation is:
 * h = f + g
 * h = 2**0*f0 + 2**64*f1 + 2**128*f2 + 2**192*f3 + 2**256*f4 +
 *     2**0*g0 + 2**64*g1 + 2**128*g2 + 2**192*g3
*/
inline fn __add54_rrs(reg u64[5] f, stack u64[4] g) -> reg u64[4]
{
  reg u64[4] h; // Result
  reg bool cf; // Carry flag
  inline int i;
  
  // Add both numbers. No carry in limb 5.
  cf, f[0] += g[0];
  for i=1 to 4
  { cf, f[i] += g[i] + cf; }
   _, f[4] += 0 + cf;

  // Multiply MSBs by 2 and later 19 to get 38
  ?{}, f[4] = #SHLD(f[4], f[3], 1);
  // Clear shifted bit
  f[3] &= mask63;
  
  // Multiply upper limb by 19, as 2^256 == 38
  ?{}, f[4] = #IMULri ( f[4], 19 );
  // Reduce result
  cf, h[0] = f[0] + f[4];
  cf, h[1] = f[1] + 0 + cf;
  cf, h[2] = f[2] + 0 + cf;
  cf, h[3] = f[3] + 0 + cf; // No carry as MSB is cleared

  return h;
}
